HW3-Hadoop-Short

Part I: 

Develop and Run Simple Queries

Step #1: Running a Query from the Hive Shell 
================================================================================================

Question: Which customers did your query identify as the winner of the $5,000 prize?

Query: 
SELECT * FROM Customers 
WHERE customer_fname LIKE 'Br%an' AND customer_city='Chicago';

Output: 
customers.customer_id	customers.customer_fname	customers.customer_lnamecustomers.customer_email	customers.customer_password	customers.customer_street	customers.customer_city	customers.customer_state	customers.customer_zipcode
5002	Bryan	Smith	XXXXXXXXX	XXXXXXXXX	3937 Cinder Circle	Chicago	IL	60620
6429	Brian	Wilson	XXXXXXXXX	XXXXXXXXX	8772 Silent Expressway	Chicago	IL	60615

Answer:
Bryan and Brian

================================================================================================


Step #2: Running a Query Directly from the Command Line 

Question: Which two product names have a price of zero? 

Query:
SELECT DISTINCT product_name 
FROM products 
WHERE product_price=0.0;

Answer:
Callaway X Hot Driver
Nike Men's Hypervenom Phantom Premium FG Socc

Terminal Output:
Query ID = cloudera_20160824201313_943e8daa-6cb2-49dd-b2f0-166f321390be
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1472094571115_0001, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1472094571115_0001/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1472094571115_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-24 20:15:16,121 Stage-1 map = 0%,  reduce = 0%
2016-08-24 20:16:41,871 Stage-1 map = 0%,  reduce = 0%
2016-08-24 20:18:03,515 Stage-1 map = 0%,  reduce = 0%
2016-08-24 20:18:18,021 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.79 sec
2016-08-24 20:18:36,561 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.86 sec
MapReduce Total cumulative CPU time: 4 seconds 860 msec
Ended Job = job_1472094571115_0001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.86 sec   HDFS Read: 73579 HDFS Write: 68 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 860 msec
OK
Callaway X Hot Driver
Nike Men's Hypervenom Phantom Premium FG Socc
Time taken: 250.388 seconds, Fetched: 2 row(s)




================================================================================================

Question​: How many customers ids are in the customers table?

Query:
SELECT COUNT(customer_id) 
FROM Customers;

Answer:
12435

Terminal output:
Query ID = cloudera_20160817185656_2079dc5e-75d4-476b-8115-1c611d21876e
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0008, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0008/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0008
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-17 18:57:01,165 Stage-1 map = 0%,  reduce = 0%
2016-08-17 18:57:20,271 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.04 sec
2016-08-17 18:57:38,949 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.9 sec
MapReduce Total cumulative CPU time: 5 seconds 900 msec
Ended Job = job_1470887531092_0008
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.9 sec   HDFS Read: 491566 HDFS Write: 6 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 900 msec
OK
12435
Time taken: 57.011 seconds, Fetched: 1 row(s)

================================================================================================

Question​: How may households are in the customers table? (Hint, try concatenating the
customers’ address and zipcode and count the number of distinct households)

Query:
SELECT COUNT
(
DISTINCT (CONCAT(
customer_street,' ','customer_city',' ',customer_state,' ',customer_zipcode))) 
FROM customers;

Answer:
11508

Terminal output:
Query ID = cloudera_20160817191010_e8e8e6f3-2b7d-4ef4-af4a-93c7dc30fe45
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0021, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0021/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0021
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-17 20:38:38,953 Stage-1 map = 0%,  reduce = 0%
2016-08-17 20:38:55,157 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 5.68 sec
2016-08-17 20:39:17,793 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 9.11 sec
MapReduce Total cumulative CPU time: 9 seconds 110 msec
Ended Job = job_1470887531092_0021
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 9.11 sec   HDFS Read: 493350 HDFS Write: 6 SUCCESS
Total MapReduce CPU Time Spent: 9 seconds 110 msec
OK
11508
Time taken: 50.603 seconds, Fetched: 1 row(s)

================================================================================================

Question​: Using customer_id, which state has the most customers? Hint: notice, you can group
by one field and then order by another. To refresh your memory on “group by”:

Query:
SELECT customer_state, 
COUNT(customer_id) ccount 
FROM customers 
GROUP BY customer_state 
ORDER BY ccount DESC LIMIT 1;

Answer:
PR	4771

Terminal output:
Query ID = cloudera_20160817204444_b7bd1be3-f9e2-430e-96f3-731bd35a469a
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0032, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0032/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0032
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-17 21:23:16,056 Stage-1 map = 0%,  reduce = 0%
2016-08-17 21:23:29,474 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.77 sec
2016-08-17 21:23:48,688 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.4 sec
MapReduce Total cumulative CPU time: 5 seconds 400 msec
Ended Job = job_1470887531092_0032
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0033, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0033/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0033
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2016-08-17 21:24:01,770 Stage-2 map = 0%,  reduce = 0%
2016-08-17 21:24:12,497 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.13 sec
2016-08-17 21:24:35,868 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.08 sec
MapReduce Total cumulative CPU time: 3 seconds 80 msec
Ended Job = job_1470887531092_0033
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.4 sec   HDFS Read: 491410 HDFS Write: 1043 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.08 sec   HDFS Read: 5801 HDFS Write: 8 SUCCESS
Total MapReduce CPU Time Spent: 8 seconds 480 msec
OK
PR	4771
Time taken: 92.492 seconds, Fetched: 1 row(s)

================================================================================================

Calculating Revenue and Profit:

Question: ​Which top three product_ids had the most orders? Show your query.
Extra credit:​ What were the product names? Show your query.

Query:
SELECT p.product_name, o.order_item_product_id, 
COUNT(o.order_item_order_id) ccount 
FROM order_items o, products p 
WHERE o.order_item_product_id=p.product_id 
GROUP BY o.order_item_product_id,p.product_name 
ORDER BY ccount DESC LIMIT 3;

Answer:
Perfect Fitness Perfect Rip Deck		365	24515
Nike Men's CJ Elite 2 TD Football Cleat	403	22246
Nike Men's Dri-FIT Victory Golf Polo	502	21035

Terminal output:
Query ID = cloudera_20160818093838_376c32e2-f290-4615-a2b2-e8a989ea8cd9
Total jobs = 2
Execution log at: /tmp/cloudera/cloudera_20160818093838_376c32e2-f290-4615-a2b2-e8a989ea8cd9.log
2016-08-18 09:49:00	Starting to launch local task to process map join;	maximum memory = 1013645312
2016-08-18 09:49:03	Dump the side-table for tag: 1 with group count: 1345 into file: file:/tmp/cloudera/79bb8b2e-f674-48a6-a674-70a16cb86385/hive_2016-08-18_09-48-52_593_3823297598226711687-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile01--.hashtable
2016-08-18 09:49:04	Uploaded 1 File to: file:/tmp/cloudera/79bb8b2e-f674-48a6-a674-70a16cb86385/hive_2016-08-18_09-48-52_593_3823297598226711687-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile01--.hashtable (81198 bytes)
2016-08-18 09:49:04	End of local task; Time Taken: 3.064 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0034, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0034/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0034
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2016-08-18 09:49:20,897 Stage-2 map = 0%,  reduce = 0%
2016-08-18 09:49:38,518 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.0 sec
2016-08-18 09:50:01,537 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 6.88 sec
MapReduce Total cumulative CPU time: 6 seconds 880 msec
Ended Job = job_1470887531092_0034
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0035, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0035/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0035
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2016-08-18 09:50:16,541 Stage-3 map = 0%,  reduce = 0%
2016-08-18 09:50:26,742 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.16 sec
2016-08-18 09:50:40,786 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.83 sec
MapReduce Total cumulative CPU time: 2 seconds 830 msec
Ended Job = job_1470887531092_0035
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 6.88 sec   HDFS Read: 1552079 HDFS Write: 5991 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.83 sec   HDFS Read: 10849 HDFS Write: 140 SUCCESS
Total MapReduce CPU Time Spent: 9 seconds 710 msec
OK
Perfect Fitness Perfect Rip Deck	365	24515
Nike Men's CJ Elite 2 TD Football Cleat	403	22246
Nike Men's Dri-FIT Victory Golf Polo	502	21035
Time taken: 109.362 seconds, Fetched: 3 row(s)

================================================================================================

Question: ​Using the orders_corrected table, count the number of orders (using order_id) that had a status 
of COMPLETE, on May 17, 2014. Show your query. 
(Notice, you can specify MONTH,YEAR and DAY as built-in functions to retreive the month, year or day from a date string).

Query:
SELECT COUNT(order_id) FROM orders_corrected 
WHERE order_status='COMPLETE' 
AND order_datestr='2014-05-17 00:00:00';

Answer:
61

Terminal output:
Query ID = cloudera_20160818093838_376c32e2-f290-4615-a2b2-e8a989ea8cd9
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0037, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0037/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0037
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-18 15:32:52,304 Stage-1 map = 0%,  reduce = 0%
2016-08-18 15:33:41,147 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.45 sec
2016-08-18 15:34:25,560 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.11 sec
MapReduce Total cumulative CPU time: 6 seconds 110 msec
Ended Job = job_1470887531092_0037
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.59 sec   HDFS Read: 3834615 HDFS Write: 3 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 590 msec
OK
61
Time taken: 125.229 seconds, Fetched: 1 row(s)

================================================================================================

Question: ​What was Dualcore’s total revenue from completed orders on May 17, 2014? (Hint:
use a left semi join). Show your query.

Query:
SELECT SUM(oi.order_item_subtotal)AS Revenue 
FROM order_items oi 
LEFT SEMI JOIN orders_corrected o 
ON (oi.order_item_order_id = o.order_id) 
AND (o.order_status='COMPLETE') 
AND (o.order_datestr='2014-05-17 00:00:00') ;


Answer:
29198.830507278442

Terminal output:
Query ID = cloudera_20160824185252_b6148dd7-7c65-4f0e-8d9a-bfa52383ca40
Total jobs = 1
Execution log at: /tmp/cloudera/cloudera_20160824185252_b6148dd7-7c65-4f0e-8d9a-bfa52383ca40.log
2016-08-24 06:59:27	Starting to launch local task to process map join;	maximum memory = 1013645312
2016-08-24 06:59:29	Dump the side-table for tag: 1 with group count: 61 into file: file:/tmp/cloudera/49c1df51-4312-4e2c-8fc1-bbc30850a797/hive_2016-08-24_18-59-18_149_5946367241986189875-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile21--.hashtable
2016-08-24 06:59:29	Uploaded 1 File to: file:/tmp/cloudera/49c1df51-4312-4e2c-8fc1-bbc30850a797/hive_2016-08-24_18-59-18_149_5946367241986189875-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile21--.hashtable (1502 bytes)
2016-08-24 06:59:29	End of local task; Time Taken: 2.465 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1472087500009_0003, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1472087500009_0003/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1472087500009_0003
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2016-08-24 18:59:42,945 Stage-2 map = 0%,  reduce = 0%
2016-08-24 18:59:55,186 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.06 sec
2016-08-24 19:00:14,492 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 5.94 sec
MapReduce Total cumulative CPU time: 5 seconds 940 msec
Ended Job = job_1472087500009_0003
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 5.94 sec   HDFS Read: 1549979 HDFS Write: 19 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 940 msec
OK
29198.830507278442
Time taken: 57.491 seconds, Fetched: 1 row(s)
================================================================================================

• The result of the above query is in scientific notation. 
Rewrite the last query to format the value in dollars and cents (e.g., $2000000.00). 
To do this, format the result using the PRINTF function and the format string "$%.2f". Show your query.

Query: 
SELECT PRINTF("$%.2f", SUM(oi.order_item_subtotal)) 
FROM order_items oi 
LEFT SEMI JOIN orders_corrected o 
ON (oi.order_item_order_id = o.order_id) 
AND (o.order_status='COMPLETE')
AND (o.order_datestr='2014-05-17 00:00:00');

Answer:
$29198.83

Terminal output:
Query ID = cloudera_20160824185252_b6148dd7-7c65-4f0e-8d9a-bfa52383ca40
Total jobs = 1
Execution log at: /tmp/cloudera/cloudera_20160824185252_b6148dd7-7c65-4f0e-8d9a-bfa52383ca40.log
2016-08-24 06:56:31	Starting to launch local task to process map join;	maximum memory = 1013645312
2016-08-24 06:56:34	Dump the side-table for tag: 1 with group count: 61 into file: file:/tmp/cloudera/49c1df51-4312-4e2c-8fc1-bbc30850a797/hive_2016-08-24_18-56-21_128_3947261538366822221-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile11--.hashtable
2016-08-24 06:56:34	Uploaded 1 File to: file:/tmp/cloudera/49c1df51-4312-4e2c-8fc1-bbc30850a797/hive_2016-08-24_18-56-21_128_3947261538366822221-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile11--.hashtable (1502 bytes)
2016-08-24 06:56:34	End of local task; Time Taken: 2.935 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1472087500009_0002, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1472087500009_0002/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1472087500009_0002
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2016-08-24 18:56:53,334 Stage-2 map = 0%,  reduce = 0%
2016-08-24 18:57:24,137 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.15 sec
2016-08-24 18:57:42,502 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.58 sec
MapReduce Total cumulative CPU time: 7 seconds 580 msec
Ended Job = job_1472087500009_0002
MapReduce Jobs Launched: 
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.58 sec   HDFS Read: 1550328 HDFS Write: 10 SUCCESS
Total MapReduce CPU Time Spent: 7 seconds 580 msec
OK
$29198.83
Time taken: 83.572 seconds, Fetched: 1 row(s)

================================================================================================

Part II: 

Data Management with Hive  
 
Question:  how many ratings are there? 

Query:
SELECT COUNT(*) FROM ratings; 

Answer:
21997

Terminal output:
Query ID = cloudera_20160819154646_e8d6db69-f06c-45c5-9635-1426c945abf0
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1470887531092_0048, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1470887531092_0048/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1470887531092_0048
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2016-08-19 16:06:01,155 Stage-1 map = 0%,  reduce = 0%
2016-08-19 16:06:12,307 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.85 sec
2016-08-19 16:06:30,767 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.75 sec
MapReduce Total cumulative CPU time: 3 seconds 750 msec
Ended Job = job_1470887531092_0048
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.75 sec   HDFS Read: 1274513 HDFS Write: 6 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 750 msec
OK
21997
Time taken: 43.774 seconds, Fetched: 1 row(s)

================================================================================================

Create, Load, and Query a Table with Complex Fields:

Create the following queries: 

Question: Show the 3 queries that you ran.
 
1. Select the HOME phone number (​Hint​: Map keys are case­sensitive) for customer ID 
1200866. You should see 408­555­4914 as the result. 

Query:
SELECT phone["HOME"] FROM loyalty_program WHERE cust_id='1200866';

Answer:
408-555-4914

Terminal output:
hive> SELECT phone["HOME"] FROM loyalty_program WHERE cust_id='1200866';
OK
408-555-4914
Time taken: 0.467 seconds, Fetched: 1 row(s)
 
================================================================================================

2. Select the third element from the order_ids array for customer ID 1200866 (​Hint​: Elements are indexed from zero). The query should return 5278505. 
 
Query:
SELECT order_ids[2] FROM loyalty_program WHERE cust_id='1200866';

Answer:
5278505

Terminal output:
hive> SELECT order_ids[2] FROM loyalty_program WHERE cust_id='1200866';
OK
5278505
Time taken: 0.067 seconds, Fetched: 1 row(s)

================================================================================================

3. Select the total attribute from the order_value struct for customer ID 1200866. The query should return 401874. 
 
Query:
SELECT order_value.total FROM loyalty_program WHERE cust_id='1200866';

Answer:
401874

Terminal output:
hive> SELECT order_value.total FROM loyalty_program WHERE cust_id='1200866';
OK
401874

================================================================================================

Alter and Drop a Table: 

Question: Show the queries that you ran for steps 1-5.
 
1.  Use ALTER TABLE to rename the ​level​ column to ​status​. 

Query: 
ALTER TABLE loyalty_program CHANGE level status STRING;

Answer:
OK

Terminal output:
hive> ALTER TABLE loyalty_program CHANGE level status STRING;
OK
Time taken: 0.486 seconds

================================================================================================
 
2.  Use the DESCRIBE command on the loyalty_program table to verify the change. 

Query:
DESCRIBE loyalty_program;

Output and Answer:
cust_id             	int                 	                    
fname               	string              	                    
lname               	string              	                    
email               	string              	                    
status              	string              	                    
phone               	map<string,string>  	                    
order_ids               array<int>          	                    
order_value           struct<min:int,max:int,avg:int,total:int>	 

Terminal output:
hive> describe loyalty_program;
OK
cust_id             	int                 	                    
fname               	string              	                    
lname               	string              	                    
email               	string              	                    
status              	string              	                    
phone               	map<string,string>  	                    
order_ids           	array<int>          	                    
order_value         	struct<min:int,max:int,avg:int,total:int>	                    
Time taken: 0.091 seconds, Fetched: 8 row(s)

================================================================================================                   
 
3.  Use ALTER TABLE to rename the entire table to reward_program. 

Query:
ALTER TABLE loyalty_program RENAME TO reward_program;

Answer:
OK

Terminal output:
hive> ALTER TABLE loyalty_program RENAME TO reward_program;
OK
Time taken: 0.596 seconds

hive> SHOW TABLES;
OK
categories
customers
departments
order_items
orders
orders_corrected
products
ratings
revenue
revenueview
reward_program
Time taken: 0.096 seconds, Fetched: 11 row(s)
 
================================================================================================

4.  Although the ALTER TABLE command often requires that we make a corresponding change to the data in HDFS, renaming a table or column does not.  
 
You can verify this by running a query on the table using the new names (the result should be “SILVER”):   

Query:
SELECT status FROM reward_program WHERE cust_id = 1200866;

Answer:
OK
SILVER

Terminal output:
hive> SELECT status FROM reward_program WHERE cust_id = 1200866;
OK
SILVER
Time taken: 0.079 seconds, Fetched: 1 row(s)

 
================================================================================================

5.  As sometimes happens in the corporate world, priorities have shifted and the program is now canceled. Drop the reward_program table. 

Query:
DROP TABLE IF EXISTS reward_program;

Output and Answer:
OK

Terminal output:
hive> DROP TABLE IF EXISTS reward_program;
OK
Time taken: 0.419 seconds

hive> SHOW TABLES;
OK
categories
customers
departments
order_items
orders
orders_corrected
products
ratings
revenue
revenueview
Time taken: 1.087 seconds, Fetched: 10 row(s)

================================================================================================

Bonus question (+5 pts) 
 
On your VM, in the ​datasets​ directory, there is a file called ​access_log.gz​ and it contains 
compressed log entries. 
 
Create a table, using RegexSerde,  to load this file into Hive.  Your new table should contain 
entries for IP address, date_and_time, request, response and bytes_read.   
 
Bonus question:  Show the query you ran to create the table. 

CREATE EXTERNAL TABLE access_log (
ip_address STRING,
date_and_time STRING,
request STRING,
response STRING,
byte_read STRING)
ROW FORMAT SERDE 'org.apache.hadoop.hive.contrib.serde2.RegexSerDe' 
WITH SERDEPROPERTIES
(
"input.regex" = "([^ ]*) ([^ ]*) ([^ ]*) (-|\\[[^\\]]*\\]) ([^ \"]*|\"[^\"]*\") 
(-|[0-9]*) (-|[0-9]*)(?: ([^ \"]*|\"[^\"]*\") ([^\"]*|\"[^\"]*\"))?",
"output.format.string" = "%1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s" 
)
STORED AS TEXTFILE 
LOCATION '/home/cloudera/datasets';


 








